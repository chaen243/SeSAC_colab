{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaen243/SeSAC_colab/blob/main/03_05_FashionMNIST_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-kYIez2VCk8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a811da7-992d-4405-8153-c63276faf3be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "your_path = \"/content/\"\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import os\n",
        "    os.chdir(your_path)\n",
        "    print(os.getcwd())\n",
        "except ModuleNotFoundError:\n",
        "    print(\"you are not in google colab, pass this phase\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U3syy9ZCyZt"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KRMx0LpDO6K"
      },
      "source": [
        "# FashionMNIST 데이터 학습 시키기\n",
        "\n",
        "FashionMNIST은 각 이미지에 대해 10개의 클래스를 분류하는 데이터셋이며, 각 이미지는 (28x28) 크기를 가진 RGB 이미지다.\n",
        "\n",
        "## 데이터 불러오기 및 전처리 파이프라인\n",
        "\n",
        "파이프라인은 한 데이터 처리 단계의 출력이 다음 단계의 입력으로 이어지는 형태로 연결된 구조를 가리킨다. 이미지 전처리 파이프라인은 `torchvision` 패키지의 `transforms`를 주로 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eJbBaiIODS_q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Tensor로 변환 (32, 32, 3) > (3, 32, 32)\n",
        "])"
      ],
      "metadata": {
        "id": "xU2hcv3hhF2n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "msaAteRBDbpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c3bb80-782b-4fc9-d98a-f021fd54d7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 115MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 5.92MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 62.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 25.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 데이터 경로\n",
        "data_path = \"./\"\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(\n",
        "    root=data_path,\n",
        "    train=True,\n",
        "    transform=img_transformer,\n",
        "    download=True)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True)\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(\n",
        "    root=data_path,\n",
        "    train=False,\n",
        "    transform=img_transformer,\n",
        "    download=True)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eaEySUIkY7Hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273b3fad-48f2-4761-8f37-2ceeb4ed7eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MptynUsEDdUL"
      },
      "outputs": [],
      "source": [
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AksW81crDeij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2d1c91-c76c-4f0e-9334-95072b195ec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "data.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_v-RJeLDgsC"
      },
      "source": [
        "## CNN 모델 (Coding Part)\n",
        "\n",
        "### 네트워크 설계\n",
        "\n",
        "* Input Size = (B, 1, 28, 28)\n",
        "* Output Size = (B, 10)\n",
        "* Activation Function(`nn.ReLU`): ReLU\n",
        "* Loss Function(`nn.CrossEntropyLoss`): Cross Entropy Loss\n",
        "* Optimizer(`optim.Adam`): Adam\n",
        "* Convolutional Layer: `self.convs` 변수의 `nn.Sequential`안에 구현\n",
        "    > Conv1\n",
        "    >\n",
        "    > 1. Conv(`nn.Conv2d`): 입력채널 1, 출력채널 8, 커널크기 3\n",
        "    > 2. ReLU(`nn.ReLU`)\n",
        "    > 3. MaxPool(`nn.MaxPool2d`): 커널크기 2\n",
        "    >\n",
        "    > Conv2\n",
        "    > 4. Conv(`nn.Conv2d`): 입력채널 8, 출력채널 16, 커널크기 3\n",
        "    > 5. ReLU(`nn.ReLU`)\n",
        "    > 6. MaxPool(`nn.MaxPool2d`): 커널크기 2\n",
        "    >\n",
        "    > Conv3\n",
        "    > 7. Conv(`nn.Conv2d`): 입력채널 16, 출력채널 32, 커널크기 3\n",
        "    > 8. ReLU(`nn.ReLU`)\n",
        "    > 9. MaxPool(`nn.MaxPool2d`): 커널크기 2\n",
        "    >\n",
        "    > Conv4\n",
        "    > 10. Conv(`nn.Conv2d`): 입력채널 32, 출력채널 64, 커널크기 3\n",
        "    > 11. ReLU(`nn.ReLU`)\n",
        "* Fully Connected Layer: `self.fc` 변수의 `nn.Sequential`안에 구현\n",
        "    > 1. Linear(`nn.Linear`): Hidden Size = 100 (**입력 뉴런수 계산 필요**)\n",
        "    > 2. ReLU(`nn.ReLU`)\n",
        "    > 3. Linear(`nn.Linear`): Hidden Size = 100\n",
        "    > 4. ReLU(`nn.ReLU`)\n",
        "    > 5. Linear(`nn.Linear`): Hidden Size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "icnwhrw2DhFQ"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        # 층을 구성\n",
        "        self.convs = nn.Sequential(\n",
        "            # Conv1\n",
        "            nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,stride=1, padding=1),\n",
        "            #[B, 1, 28, 28] -> [B, 8, 28, 28]\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Conv2\n",
        "            nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv3\n",
        "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv4\n",
        "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc = nn.Sequential( # 분류를 위한 학습층\n",
        "        nn.Linear(in_features=64*3*3,out_features=100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,10),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward propagation 수행\n",
        "        # Conv Layers\n",
        "        x = self.convs(x)\n",
        "        # x의 차원을 (미니배치, 32*3*3)에 알맞게 수정한다.\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # FC Layers\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOe7EWNJDlqw"
      },
      "source": [
        "### 손실함수 및 옵티마이저"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6vGVfHvKDmA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a86db0-bebf-4647-a669-bc120ca73fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "# 커스텀 모듈 호출\n",
        "model = Network().to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHuYhaPWDoJy"
      },
      "source": [
        "## 모델훈련\n",
        "\n",
        "### Train 함수(Coding Part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Lz_UCGYUDobk"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, loss_function, optimizer, n_train, print_step, device):\n",
        "    # Training\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
        "        data, target = data.to(device), target.to(device)\n",
        "                # 경사 초기화\n",
        "        optimizer.zero_grad()\n",
        "        # 순방향 전파. 데어터를 넣어 예측값 입력\n",
        "        output = model(data)\n",
        "        # 손실값 계산\n",
        "        loss = loss_function(output, target)\n",
        "        # 역방향 전파\n",
        "        loss.backward()\n",
        "        # 매개변수 업데이트\n",
        "        optimizer.step()\n",
        "        # 중간 과정 print\n",
        "        if batch_idx % print_step == 0:\n",
        "            percentage = (batch_idx*train_loader.batch_size / n_train) * 100\n",
        "            print(f\" - [{percentage:.2f}%] train loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW304vNsDr3N"
      },
      "source": [
        "### Validation 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "G8dHMTGRDsKt"
      },
      "outputs": [],
      "source": [
        "def validation(model, test_loader, loss_function, n_test, device):\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    # torch.no_grad 를 사용하면 requires_grad 를 꺼두게 된다.\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # 순방향전파\n",
        "            output = model(data)\n",
        "            # 손실값 계산\n",
        "            test_loss += loss_function(output, target).item()\n",
        "            # 예측 값에 해당하는 클래스 번호 반환\n",
        "            pred = output.softmax(1).argmax(dim=1, keepdim=True)\n",
        "            # 정확하게 예측한 개수를 기록한다\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_accuracy = correct / n_test\n",
        "\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련시작"
      ],
      "metadata": {
        "id": "vhStPN6za1P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = len(train_dataset)\n",
        "n_test = len(test_dataset)\n",
        "n_step = 20\n",
        "print_step = 300\n",
        "best_accuracy = 0\n",
        "\n",
        "for step in range(n_step):\n",
        "    print(f\"[Step] {step+1}/{n_step}\\n [Training Step]\")\n",
        "    train(model, train_loader, loss_function, optimizer, n_train, print_step, device)\n",
        "    test_loss, test_accuracy = validation(model, test_loader, loss_function, n_test, device)\n",
        "    print(f\" [Validation Step]\")\n",
        "    print(f\" - test loss: {test_loss:.4f} test accuracy: {test_accuracy*100:.2f} %\")\n",
        "    # 제일 성능을 보인 좋은 모델 저장하기\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        torch.save(model.state_dict(), \"best_model-cifar10.pt\")"
      ],
      "metadata": {
        "id": "V8T7XqsZa02W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f2d68f-2aa7-481a-acf7-705e106b5faa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step] 1/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.4706\n",
            " - [32.00%] train loss: 0.3492\n",
            " - [64.00%] train loss: 0.3906\n",
            " - [96.00%] train loss: 0.2816\n",
            " [Validation Step]\n",
            " - test loss: 62.3975 test accuracy: 85.39 %\n",
            "[Step] 2/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.4991\n",
            " - [32.00%] train loss: 0.1953\n",
            " - [64.00%] train loss: 0.2589\n",
            " - [96.00%] train loss: 0.3558\n",
            " [Validation Step]\n",
            " - test loss: 58.9605 test accuracy: 86.05 %\n",
            "[Step] 3/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.3044\n",
            " - [32.00%] train loss: 0.3392\n",
            " - [64.00%] train loss: 0.3379\n",
            " - [96.00%] train loss: 0.4171\n",
            " [Validation Step]\n",
            " - test loss: 51.9857 test accuracy: 87.99 %\n",
            "[Step] 4/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.3133\n",
            " - [32.00%] train loss: 0.3335\n",
            " - [64.00%] train loss: 0.3143\n",
            " - [96.00%] train loss: 0.3665\n",
            " [Validation Step]\n",
            " - test loss: 50.6847 test accuracy: 88.79 %\n",
            "[Step] 5/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.3916\n",
            " - [32.00%] train loss: 0.2774\n",
            " - [64.00%] train loss: 0.1533\n",
            " - [96.00%] train loss: 0.3291\n",
            " [Validation Step]\n",
            " - test loss: 47.4376 test accuracy: 89.07 %\n",
            "[Step] 6/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.1451\n",
            " - [32.00%] train loss: 0.4759\n",
            " - [64.00%] train loss: 0.2682\n",
            " - [96.00%] train loss: 0.2801\n",
            " [Validation Step]\n",
            " - test loss: 45.8508 test accuracy: 89.36 %\n",
            "[Step] 7/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.2407\n",
            " - [32.00%] train loss: 0.2144\n",
            " - [64.00%] train loss: 0.1186\n",
            " - [96.00%] train loss: 0.1652\n",
            " [Validation Step]\n",
            " - test loss: 46.1021 test accuracy: 89.48 %\n",
            "[Step] 8/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.1387\n",
            " - [32.00%] train loss: 0.2757\n",
            " - [64.00%] train loss: 0.2728\n",
            " - [96.00%] train loss: 0.2422\n",
            " [Validation Step]\n",
            " - test loss: 44.7011 test accuracy: 89.43 %\n",
            "[Step] 9/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.2710\n",
            " - [32.00%] train loss: 0.1196\n",
            " - [64.00%] train loss: 0.3161\n",
            " - [96.00%] train loss: 0.1538\n",
            " [Validation Step]\n",
            " - test loss: 44.0190 test accuracy: 89.75 %\n",
            "[Step] 10/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.1902\n",
            " - [32.00%] train loss: 0.1481\n",
            " - [64.00%] train loss: 0.2852\n",
            " - [96.00%] train loss: 0.0625\n",
            " [Validation Step]\n",
            " - test loss: 44.3352 test accuracy: 90.07 %\n",
            "[Step] 11/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.3059\n",
            " - [32.00%] train loss: 0.1474\n",
            " - [64.00%] train loss: 0.1680\n",
            " - [96.00%] train loss: 0.2717\n",
            " [Validation Step]\n",
            " - test loss: 44.1933 test accuracy: 89.56 %\n",
            "[Step] 12/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.2524\n",
            " - [32.00%] train loss: 0.2214\n",
            " - [64.00%] train loss: 0.0670\n",
            " - [96.00%] train loss: 0.1257\n",
            " [Validation Step]\n",
            " - test loss: 42.1021 test accuracy: 90.52 %\n",
            "[Step] 13/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.1041\n",
            " - [32.00%] train loss: 0.2951\n",
            " - [64.00%] train loss: 0.1947\n",
            " - [96.00%] train loss: 0.1750\n",
            " [Validation Step]\n",
            " - test loss: 44.8078 test accuracy: 90.00 %\n",
            "[Step] 14/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.1357\n",
            " - [32.00%] train loss: 0.2188\n",
            " - [64.00%] train loss: 0.1848\n",
            " - [96.00%] train loss: 0.0787\n",
            " [Validation Step]\n",
            " - test loss: 45.3765 test accuracy: 90.28 %\n",
            "[Step] 15/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.1072\n",
            " - [32.00%] train loss: 0.1759\n",
            " - [64.00%] train loss: 0.2295\n",
            " - [96.00%] train loss: 0.0459\n",
            " [Validation Step]\n",
            " - test loss: 44.3431 test accuracy: 90.33 %\n",
            "[Step] 16/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.2160\n",
            " - [32.00%] train loss: 0.1447\n",
            " - [64.00%] train loss: 0.1530\n",
            " - [96.00%] train loss: 0.2688\n",
            " [Validation Step]\n",
            " - test loss: 45.3159 test accuracy: 90.35 %\n",
            "[Step] 17/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.2629\n",
            " - [32.00%] train loss: 0.1155\n",
            " - [64.00%] train loss: 0.1482\n",
            " - [96.00%] train loss: 0.0858\n",
            " [Validation Step]\n",
            " - test loss: 44.7970 test accuracy: 90.55 %\n",
            "[Step] 18/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.1079\n",
            " - [32.00%] train loss: 0.1045\n",
            " - [64.00%] train loss: 0.1704\n",
            " - [96.00%] train loss: 0.0632\n",
            " [Validation Step]\n",
            " - test loss: 49.3666 test accuracy: 89.43 %\n",
            "[Step] 19/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.0701\n",
            " - [32.00%] train loss: 0.0477\n",
            " - [64.00%] train loss: 0.1295\n",
            " - [96.00%] train loss: 0.3576\n",
            " [Validation Step]\n",
            " - test loss: 47.7112 test accuracy: 90.47 %\n",
            "[Step] 20/20\n",
            " [Training Step]\n",
            " - [0.00%] train loss: 0.1128\n",
            " - [32.00%] train loss: 0.2591\n",
            " - [64.00%] train loss: 0.2547\n",
            " - [96.00%] train loss: 0.0861\n",
            " [Validation Step]\n",
            " - test loss: 48.1049 test accuracy: 90.42 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pL6vx6fZ7mCr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}