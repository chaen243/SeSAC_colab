{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaen243/SeSAC_colab/blob/main/03_09_ResNet_exp_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dVKLyLt-SfWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55b863eb-1450-469c-b8ed-d92b1c03e40f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import tqdm\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "id": "VYgyKc_qSvgs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKqguG%2FbtqAyyU6Dlp%2F4k2pZ9IiJeZT3lB0KBotgK%2Fimg.png)"
      ],
      "metadata": {
        "id": "XpnVRrJ9SZsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Convolution Operation  \n",
        "PyTorch에서는 [nn.sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) 등의 함수를 이용해서 복잡한 모델 구조를 종종 축약해서 사용하곤 합니다.\n",
        "\n",
        "아래의 예제는 conv-relu-maxpool의 model을 서로 다른 방법으로 표현한 것입니다."
      ],
      "metadata": {
        "id": "BcuV98cpS_cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(64, 3, 32, 32)\n",
        "input_image.shape"
      ],
      "metadata": {
        "id": "pvdSFr_USw0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c6332e-6ccb-4450-8128-f728e2eaf195"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Sequential"
      ],
      "metadata": {
        "id": "tDLBHntSTL72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "conv2d - ReLU - MaxPool2d순으로 쌓아주세요!  \n",
        "`nn.Conv2d`는 `input_channel`3, `output_channel`64 `kernel_size`3 로 쌓아주세요.\n",
        "\n",
        "Conv1,2,3은 각각 다른 스타일로 설계해주세요!\n",
        "- Conv1클래스는 변수에 모델 설계\n",
        "- Conv2클래스는 `nn.Sequential`로 모델 설계\n",
        "- Conv3클래스는 list append로 모델 설계"
      ],
      "metadata": {
        "id": "Ehe0YcNwg8-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `nn.Conv2d`\n",
        "  - 사용예제 `nn.Conv2d(input_channel, output_channel, kernel_size, padding)`\n",
        "- `nn.ReLU()`\n",
        "- `nn.MaxPool2d(kernel_size)`"
      ],
      "metadata": {
        "id": "n0IA1pPQpOB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1(nn.Module):\n",
        "    def __init__(self): # input image = batch_size x 3 x 32 x 32\n",
        "        super(Conv1, self).__init__()\n",
        "        self.conv = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv2(nn.Module):\n",
        "    def __init__(self): # input image = batch_size x 3 x 32 x 32\n",
        "        super(Conv2, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv3(nn.Module):\n",
        "    def __init__(self): # input image = batch_size x 3 x 32 x 32\n",
        "        super(Conv3, self).__init__()\n",
        "        layer = []\n",
        "        layer.append(nn.Conv2d(3,64,3,padding=1))\n",
        "        layer.append(nn.ReLU())\n",
        "        layer.append(nn.MaxPool2d(2))\n",
        "        self.layer = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "        return x\n",
        "\n",
        "model1 = Conv1()\n",
        "model2 = Conv2()\n",
        "model3 = Conv3()"
      ],
      "metadata": {
        "id": "dCU5QAYRTKgW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model1)\n",
        "output = model1(input_image)\n",
        "print(output.size())"
      ],
      "metadata": {
        "id": "kdlV36qATNwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71be2a05-ef56-4c84-dd50-8e51e7243d0a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1(\n",
            "  (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu): ReLU()\n",
            "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "torch.Size([64, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model2)\n",
        "output = model2(input_image)\n",
        "print(output.size())"
      ],
      "metadata": {
        "id": "ux7rJjBVTO-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83aa4073-5c2e-4d82-e8d5-e0b978a076c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2(\n",
            "  (layer): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            ")\n",
            "torch.Size([64, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model3)\n",
        "output = model3(input_image)\n",
        "print(output.size())"
      ],
      "metadata": {
        "id": "gRJG_HeUTP5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c096d65-2739-4d09-dfb7-1ffd9b45cd4f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv3(\n",
            "  (layer): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            ")\n",
            "torch.Size([64, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's practice to calculate the shape of the network"
      ],
      "metadata": {
        "id": "II5uWbWTTS7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://d3s0tskafalll9.cloudfront.net/media/images/GC-1-P-table1.max-800x600.png)"
      ],
      "metadata": {
        "id": "FtbcKA8BS61Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에 있는 그림 중 34-layer에 해당하는 resnet을 구현해놓은 예제입니다.  \n",
        "빈칸에 알맞은 변수이름을 넣으시거나, 새롭게 구현하셔도 무방합니다!"
      ],
      "metadata": {
        "id": "Yh72mWmPiZ_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv_block(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size=3, strides=1, activation=True): # input image = batch_size x 3 x 32 x 32\n",
        "        super(Conv_block, self).__init__()\n",
        "        self.in_dim = input_dim\n",
        "        self.out_dim = output_dim\n",
        "        self.activation = activation\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(self.in_dim, self.out_dim, kernel_size=self.kernel_size, stride=self.strides, padding=self.kernel_size // 2, bias=False),\n",
        "            nn.BatchNorm2d(self.out_dim)  # Batch Normalization\n",
        "        )\n",
        "        # conv와 batch만 넘깁니다.\n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "        if self.activation:\n",
        "            x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ccSnfVYzTRJQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Build_resnet_block(nn.Module):\n",
        "    def __init__(self, num_layer, input_dim=3, output_dim=64, block_num=0):\n",
        "        super(Build_resnet_block, self).__init__()\n",
        "        self.num_layer = num_layer\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.block_num = block_num\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv_block =  Conv_block(self.input_dim, self.output_dim, kernel_size=1, strides=2, activation=False)\n",
        "        self.blocks = nn.ModuleList()\n",
        "\n",
        "        for idx in range(self.num_layer):\n",
        "            if self.block_num > 0 and idx == 0:\n",
        "                self.blocks.append(Conv_block(self.input_dim, self.output_dim, kernel_size=3,strides=2))\n",
        "                # self.blocks.append(Conv_block(self.output_dim, self.output_dim, kernel_size=3, stride=1))\n",
        "            else:\n",
        "                self.blocks.append(Conv_block(self.output_dim, self.output_dim, kernel_size=3, strides=1))\n",
        "                # self.blocks.append(Conv_block(None))\n",
        "                # self.blocks.append(Conv_block(None))\n",
        "\n",
        "    def forward(self, x):\n",
        "        st = 0\n",
        "        for idx in range(self.num_layer):\n",
        "            if self.block_num > 0 and idx == 0:\n",
        "                shorcut = self.conv_block(x)\n",
        "                for block in self.blocks[st:st+2]:\n",
        "                    x = block(x)\n",
        "                st = st+2\n",
        "            else:\n",
        "                shorcut = x\n",
        "                for block in self.blocks[st:st+2]:\n",
        "                    x = block(x)\n",
        "                st = st+2\n",
        "            x = x + shorcut\n",
        "            x = self.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sKwgbPjVZi4e"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalAvgPool2d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GlobalAvgPool2d, self).__init__()\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        # 배치와 채널을 유지하면서 2D 공간 차원을 제거합니다.\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FWqGJK3F1UIT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Build_resnet(nn.Module):\n",
        "    def __init__(self, num_cnn_list=[3,4,6,3],\n",
        "                 channel_list=[64,128,256,512],\n",
        "                 num_classes=10,\n",
        "                 activation=\"softmax\"):\n",
        "        super(Build_resnet, self).__init__()\n",
        "        self.num_cnn_list = num_cnn_list\n",
        "        self.channel_list = channel_list\n",
        "        self.num_classes = num_classes\n",
        "        self.conv_layer = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool_layer = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.global_avg_pool = GlobalAvgPool2d()\n",
        "        self.linear = nn.Linear(512, self.num_classes)\n",
        "\n",
        "        self.resnet_blocks = nn.ModuleList()\n",
        "\n",
        "        assert len(self.num_cnn_list) == len(self.channel_list)\n",
        "\n",
        "        input_dim = 64\n",
        "        for block_num, (num_cnn, output_dim) in enumerate(zip(num_cnn_list, channel_list)):\n",
        "            block = Build_resnet_block(num_cnn, input_dim = input_dim, output_dim= output_dim, block_num=block_num)\n",
        "            self.resnet_blocks.append(block)\n",
        "            input_dim = output_dim\n",
        "\n",
        "        # Global Average Pooling 및 Fully Connected Layer\n",
        "        self.global_avg_pool = GlobalAvgPool2d()\n",
        "        self.linear = nn.Linear(512, self.num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # first layer\n",
        "        x = self.conv_layer(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool_layer(x)\n",
        "\n",
        "\n",
        "\n",
        "        for block in self.resnet_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "9dBx4FtSsiKc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  Build_resnet()"
      ],
      "metadata": {
        "id": "N16lYw882Kvr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "SBp_Eahc2NVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a2a19c-e766-4dc0-b236-1878ed216af2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build_resnet(\n",
            "  (conv_layer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (maxpool_layer): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (global_avg_pool): GlobalAvgPool2d(\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (resnet_blocks): ModuleList(\n",
            "    (0): Build_resnet_block(\n",
            "      (relu): ReLU()\n",
            "      (conv_block): Conv_block(\n",
            "        (relu): ReLU()\n",
            "        (layer): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (blocks): ModuleList(\n",
            "        (0-2): 3 x Conv_block(\n",
            "          (relu): ReLU()\n",
            "          (layer): Sequential(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Build_resnet_block(\n",
            "      (relu): ReLU()\n",
            "      (conv_block): Conv_block(\n",
            "        (relu): ReLU()\n",
            "        (layer): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (blocks): ModuleList(\n",
            "        (0): Conv_block(\n",
            "          (relu): ReLU()\n",
            "          (layer): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1-3): 3 x Conv_block(\n",
            "          (relu): ReLU()\n",
            "          (layer): Sequential(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): Build_resnet_block(\n",
            "      (relu): ReLU()\n",
            "      (conv_block): Conv_block(\n",
            "        (relu): ReLU()\n",
            "        (layer): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (blocks): ModuleList(\n",
            "        (0): Conv_block(\n",
            "          (relu): ReLU()\n",
            "          (layer): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1-5): 5 x Conv_block(\n",
            "          (relu): ReLU()\n",
            "          (layer): Sequential(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Build_resnet_block(\n",
            "      (relu): ReLU()\n",
            "      (conv_block): Conv_block(\n",
            "        (relu): ReLU()\n",
            "        (layer): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (blocks): ModuleList(\n",
            "        (0): Conv_block(\n",
            "          (relu): ReLU()\n",
            "          (layer): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1-2): 2 x Conv_block(\n",
            "          (relu): ReLU()\n",
            "          (layer): Sequential(\n",
            "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_image)\n",
        "print(output.size())"
      ],
      "metadata": {
        "id": "aTXYGWFD4SVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da9c389-8264-4b10-f6d2-05b231e6fb3c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Implementations"
      ],
      "metadata": {
        "id": "v7xeonA4Q-am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters()"
      ],
      "metadata": {
        "id": "CuHcugGgQ-rS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601a4138-4380-4086-ae0f-cd846b0f0fcd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7845f27607b0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train CIFAR-10 with own ResNet\n",
        "\n",
        "train-image: 50,000\n",
        "test-image: 10,000\n",
        "\n",
        "class: [비행기, 자동차, 트럭, 개구리, ...] 등 10개의 class\n",
        "\n",
        "for more info, https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "ZVHMQkpmRWVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use pre-defined dataset\n",
        "\n",
        "PyTorch는 custom dataset과 dataloader를 사용해도 되지만 cifar-10과 같은 유명 데이터셋에 대해서는 pre-defined된 dataset이 존재합니다.\n",
        "\n",
        "이번 실습에서는 custom dataset을 직접 만드는 대신 pre-trained dataset을 불러와서 실습을 진행해보도록 하겠습니다."
      ],
      "metadata": {
        "id": "V-ycpsCURYpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data/',\n",
        "                                 train=True,\n",
        "                                 transform=transforms.ToTensor(),\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data/',\n",
        "                                train=False,\n",
        "                                transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "cKMb75wZRMIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a383d58b-d1ab-4619-b3aa-a8f9a311b552"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self, trainloader, testloader, model, optimizer, criterion, device):\n",
        "        \"\"\"\n",
        "        trainloader: train data's loader\n",
        "        testloader: test data's loader\n",
        "        model: model to train\n",
        "        optimizer: optimizer to update your model\n",
        "        criterion: loss function\n",
        "        \"\"\"\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "\n",
        "    def train(self, epoch = 1):\n",
        "        self.model.train()\n",
        "        loss_list = []\n",
        "        acc_list = []\n",
        "        for e in range(epoch):\n",
        "            running_loss, running_acc = 0.0, 0.0\n",
        "            for i, data in tqdm.tqdm(enumerate(self.trainloader, 0)):\n",
        "                inputs, labels = data\n",
        "                # model에 input으로 tensor를 gpu-device로 보낸다\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                # zero the parameter gradients\n",
        "                self.optimizer.zero_grad()\n",
        "                # forward + backward + optimize\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "                pred = outputs.max(1, keepdim=True)[1]\n",
        "                running_acc += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "            running_loss = running_loss / len(self.trainloader)\n",
        "            running_acc = running_acc / len(self.trainloader.dataset)\n",
        "            loss_list.append(running_loss) # epoch loss\n",
        "            acc_list.append(running_acc) # epoch acc\n",
        "            print('epoch: %d  loss: %.3f  acc:%.3f' % (e + 1, running_loss, running_acc))\n",
        "\n",
        "        return loss_list, acc_list\n",
        "\n",
        "    def test(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            output = self.model(inputs)\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        test_acc = correct / len(self.testloader.dataset)\n",
        "        print('test_acc: %.3f' %(test_acc))"
      ],
      "metadata": {
        "id": "ZcHXnq2LRaVm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  Build_resnet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "WjogHDX9Rdta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f069da7c-b442-497f-b550-ac9ca6ed13a9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Build_resnet(\n",
              "  (conv_layer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "  (maxpool_layer): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (global_avg_pool): GlobalAvgPool2d(\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (resnet_blocks): ModuleList(\n",
              "    (0): Build_resnet_block(\n",
              "      (relu): ReLU()\n",
              "      (conv_block): Conv_block(\n",
              "        (relu): ReLU()\n",
              "        (layer): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (blocks): ModuleList(\n",
              "        (0-2): 3 x Conv_block(\n",
              "          (relu): ReLU()\n",
              "          (layer): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): Build_resnet_block(\n",
              "      (relu): ReLU()\n",
              "      (conv_block): Conv_block(\n",
              "        (relu): ReLU()\n",
              "        (layer): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (blocks): ModuleList(\n",
              "        (0): Conv_block(\n",
              "          (relu): ReLU()\n",
              "          (layer): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1-3): 3 x Conv_block(\n",
              "          (relu): ReLU()\n",
              "          (layer): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): Build_resnet_block(\n",
              "      (relu): ReLU()\n",
              "      (conv_block): Conv_block(\n",
              "        (relu): ReLU()\n",
              "        (layer): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (blocks): ModuleList(\n",
              "        (0): Conv_block(\n",
              "          (relu): ReLU()\n",
              "          (layer): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x Conv_block(\n",
              "          (relu): ReLU()\n",
              "          (layer): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): Build_resnet_block(\n",
              "      (relu): ReLU()\n",
              "      (conv_block): Conv_block(\n",
              "        (relu): ReLU()\n",
              "        (layer): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (blocks): ModuleList(\n",
              "        (0): Conv_block(\n",
              "          (relu): ReLU()\n",
              "          (layer): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1-2): 2 x Conv_block(\n",
              "          (relu): ReLU()\n",
              "          (layer): Sequential(\n",
              "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(trainloader = train_loader,\n",
        "                  testloader = test_loader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "loss_list, acc_list = trainer.train(epoch = 14)"
      ],
      "metadata": {
        "id": "fzcFeMlmRjXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6f308a-f03e-43b7-a94d-9ba55049e507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "503it [00:16, 32.64it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(10)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "axs[0].plot(x, loss_list)\n",
        "axs[0].set_xlabel('epoch')\n",
        "axs[0].set_title('loss_plot')\n",
        "\n",
        "axs[1].plot(x, acc_list)\n",
        "axs[1].set_xlabel('epoch')\n",
        "axs[1].set_title('acc_plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gHNz_vEERzMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test()"
      ],
      "metadata": {
        "id": "AHMsYpCGR1T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WSsBAQ1hR25C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}